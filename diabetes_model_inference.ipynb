{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295b862d-8633-4796-95b5-56cb45f59481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\r\n",
      "  Downloading mlflow-2.18.0-py3-none-any.whl (27.3 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/27.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/27.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/27.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/27.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/27.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/27.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/27.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/27.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/27.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/27.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/27.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/27.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m20.0/27.3 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m24.0/27.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting graphene<4\r\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting alembic!=1.10.0,<2\r\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting markdown<4,>=3.3\r\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.23.5)\r\n",
      "Requirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.7.0)\r\n",
      "Requirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.10.0)\r\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.1.2)\r\n",
      "Requirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.5.3)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.1.1)\r\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\r\n",
      "Collecting mlflow-skinny==2.18.0\r\n",
      "  Downloading mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m178.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gunicorn<24\r\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sqlalchemy<3,>=1.4.0\r\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/3.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m2.9/3.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting docker<8,>=4.0.0\r\n",
      "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/147.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting Flask<4\r\n",
      "  Downloading flask-3.1.0-py3-none-any.whl (102 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/103.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow-skinny==2.18.0->mlflow) (4.6.4)\r\n",
      "Collecting opentelemetry-api<3,>=1.9.0\r\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (8.0.4)\r\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (0.20.0)\r\n",
      "Collecting cloudpickle<4\r\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\r\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0\r\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/118.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pyyaml<7,>=5.1\r\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/751.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (5.3.2)\r\n",
      "Requirement already satisfied: packaging<25 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (23.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (2.28.1)\r\n",
      "Collecting gitpython<4,>=3.1.9\r\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/207.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: protobuf<6,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.18.0->mlflow) (4.25.5)\r\n",
      "Collecting sqlparse<1,>=0.4.0\r\n",
      "  Downloading sqlparse-0.5.2-py3-none-any.whl (44 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /databricks/python3/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.4.0)\r\n",
      "Collecting Mako\r\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.14)\r\n",
      "Collecting blinker>=1.9\r\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\r\n",
      "Collecting Werkzeug>=3.1\r\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting itsdangerous>=2.2\r\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\r\n",
      "Collecting click<9,>=7.0\r\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting graphql-relay<3.3,>=3.1\r\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\r\n",
      "Collecting graphql-core<3.3,>=3.1\r\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/203.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.10/site-packages (from graphene<4->mlflow) (2.8.2)\r\n",
      "Collecting typing-extensions>=4\r\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.0.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<3->mlflow) (2022.7)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (2.2.0)\r\n",
      "Collecting greenlet!=0.4.17\r\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/599.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.28.1)\r\n",
      "Collecting gitdb<5,>=4.0.1\r\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting importlib-metadata!=4.7.0,<9,>=3.7.0\r\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\r\n",
      "Collecting deprecated>=1.2.6\r\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Collecting zipp>=3.20\r\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\r\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2\r\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2.0.4)\r\n",
      "Collecting wrapt<2,>=1.10\r\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/82.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\r\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.5.1)\r\n",
      "Installing collected packages: zipp, wrapt, Werkzeug, typing-extensions, sqlparse, smmap, pyyaml, markdown, Mako, itsdangerous, gunicorn, greenlet, graphql-core, cloudpickle, click, blinker, sqlalchemy, importlib-metadata, graphql-relay, gitdb, Flask, docker, deprecated, opentelemetry-api, graphene, gitpython, alembic, opentelemetry-semantic-conventions, opentelemetry-sdk, mlflow-skinny, mlflow\r\n",
      "  Attempting uninstall: zipp\r\n",
      "    Found existing installation: zipp 1.0.0\r\n",
      "    Not uninstalling zipp at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\r\n",
      "    Can't uninstall 'zipp'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.4.0\r\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\r\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: click\r\n",
      "    Found existing installation: click 8.0.4\r\n",
      "    Not uninstalling click at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\r\n",
      "    Can't uninstall 'click'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: blinker\r\n",
      "    Found existing installation: blinker 1.4\r\n",
      "    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\r\n",
      "    Can't uninstall 'blinker'. No files were found to uninstall.\r\n",
      "  Attempting uninstall: importlib-metadata\r\n",
      "    Found existing installation: importlib-metadata 4.6.4\r\n",
      "    Not uninstalling importlib-metadata at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\r\n",
      "    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\r\n",
      "Successfully installed Flask-3.1.0 Mako-1.3.6 Werkzeug-3.1.3 alembic-1.14.0 blinker-1.9.0 click-8.1.7 cloudpickle-3.1.0 deprecated-1.2.15 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 greenlet-3.1.1 gunicorn-23.0.0 importlib-metadata-8.5.0 itsdangerous-2.2.0 markdown-3.7 mlflow-2.18.0 mlflow-skinny-2.18.0 opentelemetry-api-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 pyyaml-6.0.2 smmap-5.0.1 sqlalchemy-2.0.36 sqlparse-0.5.2 typing-extensions-4.12.2 wrapt-1.17.0 zipp-3.21.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting flaml\n",
      "  Downloading FLAML-2.3.2-py3-none-any.whl (313 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 313.9/313.9 kB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: NumPy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from flaml) (1.23.5)\n",
      "Installing collected packages: flaml\n",
      "Successfully installed flaml-2.3.2\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: flaml[automl] in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: NumPy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.1.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.5.3)\n",
      "Collecting lightgbm>=2.3.1\n",
      "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.4.1 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.10.0)\n",
      "Collecting xgboost<3.0.0,>=0.90\n",
      "  Downloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.9/153.9 MB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->flaml[automl]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->flaml[automl]) (2.2.0)\n",
      "Collecting nvidia-nccl-cu12\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.0/199.0 MB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml[automl]) (1.16.0)\n",
      "Installing collected packages: nvidia-nccl-cu12, xgboost, lightgbm\n",
      "Successfully installed lightgbm-4.5.0 nvidia-nccl-cu12-2.23.4 xgboost-2.1.3\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: flaml[automl] in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: NumPy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.5.3)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from flaml[automl]) (4.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.1.1)\n",
      "Requirement already satisfied: xgboost<3.0.0,>=0.90 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from flaml[automl]) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->flaml[automl]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->flaml[automl]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from xgboost<3.0.0,>=0.90->flaml[automl]) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml[automl]) (1.16.0)\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: flaml[automl] in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /databricks/python3/lib/python3.10/site-packages (3.7.0)\n",
      "Collecting openml\n",
      "  Downloading openml-0.15.0-py3-none-any.whl (157 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.0/158.0 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: NumPy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /databricks/python3/\n",
      "\n",
      "*** WARNING: max output size exceeded, skipping output. ***\n",
      "\n",
      "1.0.0 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /databricks/python3/lib/python3.10/site-packages (from flaml[automl]) (1.10.0)\n",
      "Requirement already satisfied: xgboost<3.0.0,>=0.90 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from flaml[automl]) (2.1.3)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from flaml[automl]) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pyarrow in /databricks/python3/lib/python3.10/site-packages (from openml) (8.0.0)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting minio\n",
      "  Downloading minio-7.2.12-py3-none-any.whl (94 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.3/94.3 kB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from openml) (2.28.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.1.4->flaml[automl]) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->flaml[automl]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->flaml[automl]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from xgboost<3.0.0,>=0.90->flaml[automl]) (2.23.4)\n",
      "Requirement already satisfied: urllib3 in /databricks/python3/lib/python3.10/site-packages (from minio->openml) (1.26.14)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from minio->openml) (4.12.2)\n",
      "Requirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from minio->openml) (2022.12.7)\n",
      "Requirement already satisfied: argon2-cffi in /databricks/python3/lib/python3.10/site-packages (from minio->openml) (21.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->openml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->openml) (3.4)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /databricks/python3/lib/python3.10/site-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.21)\n",
      "Building wheels for collected packages: liac-arff\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=97701c0bea048a0daaa9700fe286ba305779b5653ea86c992231d97cceffc4ac\n",
      "  Stored in directory: /home/spark-82de2c05-541a-4730-a5d3-aa/.cache/pip/wheels/df/2d/e9/05702e5ac2ac33a006f12c36e9b8f32f59f0050a616978ec31\n",
      "Successfully built liac-arff\n",
      "Installing collected packages: xmltodict, tqdm, pycryptodome, liac-arff, minio, openml\n",
      "Successfully installed liac-arff-2.5.0 minio-7.2.12 openml-0.15.0 pycryptodome-3.21.0 tqdm-4.67.1 xmltodict-0.14.2\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting evidently\n",
      "  Downloading evidently-0.4.40-py3-none-any.whl (3.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 13.9 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2024.6.1\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 179.6/179.6 kB 22.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ujson>=5.4.0 in /databricks/python3/lib/python3.10/site-packages (from evidently) (5.4.0)\n",
      "Collecting nltk>=3.6.7\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 30.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from evidently) (1.1.1)\n",
      "Collecting urllib3>=1.26.19\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.3/126.3 kB 19.9 MB/s eta 0:00:00\n",
      "Collecting dynaconf>=3.2.4\n",
      "  Downloading dynaconf-3.2.6-py2.py3-none-any.whl (231 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 231.1/231.1 kB 24.6 MB/s eta 0:00:00\n",
      "Collecting deprecation>=2.1.0\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting watchdog>=3.0.0\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.1/79.1 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting typer>=0.3\n",
      "  Downloading typer-0.14.0-py3-none-any.whl (44 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.7/44.7 kB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.10.0 in /databricks/python3/lib/python3.10/site-packages (from evidently) (1.10.0)\n",
      "Collecting uvicorn[standard]>=0.22.0\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 10.2 MB/s eta 0:00:00\n",
      "Collecting pydantic>=1.10.13\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 456.4/456.4 kB 24.1 MB/s eta 0:00:00\n",
      "Collecting cryptography>=43.0.1\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 45.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas[parquet]>=1.3.5 in /databricks/python3/lib/python3.10/site-packages (from evidently) (1.5.3)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in /databricks/python3/lib/python3.10/site-packages (from evidently) (0.13.5)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from evidently) (6.0.2)\n",
      "Collecting litestar>=2.8.3\n",
      "  Downloading litestar-2.13.0-py3-none-any.whl (555 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 555.5/555.5 kB 39.9 MB/s eta 0:00:00\n",
      "Collecting uuid6>=2024.7.10\n",
      "  Downloading uuid6-2024.7.10-py3-none-any.whl (6.4 kB)\n",
      "Collecting iterative-telemetry>=0.0.5\n",
      "  Downloading iterative_telemetry-0.0.9-py3-none-any.whl (10 kB)\n",
      "Collecting plotly>=5.10.0\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.1/19.1 MB 75.9 MB/s eta 0:00:00\n",
      "Collecting typing-inspect>=0.9.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting rich>=13\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.4/242.4 kB 43.8 MB/s eta 0:00:00\n",
      "Collecting requests>=2.32.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 kB 19.1 MB/s eta 0:00:00\n",
      "Collecting certifi>=2024.7.4\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.3/167.3 kB 37.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.1,>=1.22.0 in /databricks/python3/lib/python3.10/site-packages (from evidently) (1.23.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=43.0.1->evidently) (1.15.1)\n",
      "Requirement already satisfied: packaging in /databricks/python3/lib/python3.10/site-packages (from deprecation>=2.1.0->evidently) (23.2)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from iterative-telemetry>=0.0.5->evidently) (3.16.1)\n",
      "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from iterative-telemetry>=0.0.5->evidently) (1.7.0)\n",
      "Collecting multidict>=6.0.2\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.6/124.6 kB 28.4 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: anyio>=3 in /databricks/python3/lib/python3.10/site-packages (from litestar>=2.8.3->evidently) (3.5.0)\n",
      "Collecting rich-click\n",
      "  Downloading rich_click-1.8.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from litestar>=2.8.3->evidently) (4.12.2)\n",
      "Collecting httpx>=0.22\n",
      "  Downloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.6/73.6 kB 16.7 MB/s eta 0:00:00\n",
      "Collecting polyfactory>=2.6.3\n",
      "  Downloading polyfactory-2.18.1-py3-none-any.whl (59 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.3/59.3 kB 14.2 MB/s eta 0:00:00\n",
      "Collecting msgspec>=0.18.2\n",
      "  Downloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.3/210.3 kB 54.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from litestar>=2.8.3->evidently) (8.1.7)\n",
      "Collecting litestar-htmx>=0.3.0\n",
      "  Downloading litestar_htmx-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 69.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from nltk>=3.6.7->evidently) (4.67.1)\n",
      "Requirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.6.7->evidently) (1.2.0)\n",
      "WARNING: pandas 1.5.3 does not provide the extra 'parquet'\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas[parquet]>=1.3.5->evidently) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas[parquet]>=1.3.5->evidently) (2022.7)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from plotly>=5.10.0->evidently) (8.1.0)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.1\n",
      "  Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 50.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.32.0->evidently) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.32.0->evidently) (3.4)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 118.3 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 25.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn>=1.0.1->evidently) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /databricks/python3/lib/python3.10/site-packages (from statsmodels>=0.12.2->evidently) (0.5.3)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.9.0->evidently) (0.4.3)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 16.8 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.6/442.6 kB 84.6 MB/s eta 0:00:00\n",
      "Collecting httptools>=0.6.3\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.1/442.1 kB 45.5 MB/s eta 0:00:00\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 136.8 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.2/168.2 kB 42.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio>=3->litestar>=2.8.3->evidently) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=43.0.1->evidently) (2.21)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 21.7 MB/s eta 0:00:00\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels>=0.12.2->evidently) (1.16.0)\n",
      "Collecting faker\n",
      "  Downloading Faker-33.1.0-py3-none-any.whl (1.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 122.3 MB/s eta 0:00:00\n",
      "Installing collected packages: appdirs, websockets, watchdog, uvloop, uuid6, urllib3, typing-inspect, shellingham, regex, python-dotenv, pygments, pydantic-core, plotly, multidict, msgspec, mdurl, litestar-htmx, httptools, h11, fsspec, exceptiongroup, dynaconf, deprecation, certifi, annotated-types, watchfiles, uvicorn, requests, pydantic, nltk, markdown-it-py, httpcore, faker, cryptography, rich, polyfactory, iterative-telemetry, httpx, typer, rich-click, litestar, evidently\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.14\n",
      "    Not uninstalling urllib3 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Not uninstalling pygments at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'Pygments'. No files were found to uninstall.\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 5.9.0\n",
      "    Not uninstalling plotly at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'plotly'. No files were found to uninstall.\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Not uninstalling certifi at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'certifi'. No files were found to uninstall.\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Not uninstalling requests at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'requests'. No files were found to uninstall.\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.6\n",
      "    Not uninstalling pydantic at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'pydantic'. No files were found to uninstall.\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 39.0.1\n",
      "    Not uninstalling cryptography at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66\n",
      "    Can't uninstall 'cryptography'. No files were found to uninstall.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.27.96 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\n",
      "Successfully installed annotated-types-0.7.0 appdirs-1.4.4 certifi-2024.8.30 cryptography-44.0.0 deprecation-2.1.0 dynaconf-3.2.6 evidently-0.4.40 exceptiongroup-1.2.2 faker-33.1.0 fsspec-2024.10.0 h11-0.14.0 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.0 iterative-telemetry-0.0.9 litestar-2.13.0 litestar-htmx-0.4.0 markdown-it-py-3.0.0 mdurl-0.1.2 msgspec-0.18.6 multidict-6.1.0 nltk-3.9.1 plotly-5.24.1 polyfactory-2.18.1 pydantic-2.10.2 pydantic-core-2.27.1 pygments-2.18.0 python-dotenv-1.0.1 regex-2024.11.6 requests-2.32.3 rich-13.9.4 rich-click-1.8.4 shellingham-1.5.4 typer-0.14.0 typing-inspect-0.9.0 urllib3-2.2.3 uuid6-2024.7.10 uvicorn-0.32.1 uvloop-0.21.0 watchdog-6.0.0 watchfiles-1.0.0 websockets-14.1\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 839.8 kB/s eta 0:00:00\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 91.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 18.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 3.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82de2c05-541a-4730-a5d3-aa4121205b66/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 44.3 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 76.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 92.8 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 110.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 106.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 92.4 MB/s eta 0:00:00\n",
      "Collecting triton==3.1.0\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 94.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Installing collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mlflow\n",
    "!pip install scikit-learn\n",
    "!pip install flaml\n",
    "!pip install \"flaml[automl]\"\n",
    "!pip install flaml[automl]\n",
    "%pip install flaml[automl] matplotlib openml\n",
    "!pip install evidently\n",
    "!pip install torch\n",
    "!pip install --upgrade typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad381b7a-64cb-4b6d-87fb-5a22a047010b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf10e4b0-5017-4b9e-87ed-452fc60e261a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import fbeta_score, f1_score, recall_score, precision_score, make_scorer, accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import requests\n",
    "import json\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset\n",
    "from evidently import ColumnMapping\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, precision_score, recall_score\n",
    "import torch\n",
    "from evidently.ui.workspace.cloud import CloudWorkspace\n",
    "from evidently.ui.dashboards import DashboardPanelPlot, ReportFilter, PanelValue, TestFilter, TestSuitePanelType, DashboardPanelTestSuite, PlotType\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76205044-248a-4cb4-87fc-9e48c1cbbb71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define input parameters for the notebook\n",
    "dbutils.widgets.text(\"data_csv\", \"\")  # For the CSV file path\n",
    "dbutils.widgets.text(\"model_endpoint\", \"\")  # For the model endpoint URL\n",
    "dbutils.widgets.text(\"access_token\", \"\")  # For the access token\n",
    "\n",
    "# Retrieve the values of the parameters\n",
    "data_csv = dbutils.widgets.get(\"data_csv\")\n",
    "model_endpoint = dbutils.widgets.get(\"model_endpoint\")\n",
    "access_token = dbutils.widgets.get(\"access_token\")\n",
    "\n",
    "# Print the retrieved parameters (for debugging purposes)\n",
    "print(f\"Data CSV Path: {data_csv}\")\n",
    "print(f\"Model Endpoint: {model_endpoint}\")\n",
    "print(f\"Access Token: {access_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d1a9adb-b08c-47d4-ba8a-02881df6537e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck  ...  Sex   Age  Education  Income\n",
       "0              0.0     1.0       0.0        1.0  ...  1.0   4.0        6.0     8.0\n",
       "1              0.0     1.0       1.0        1.0  ...  1.0  12.0        6.0     8.0\n",
       "2              0.0     0.0       0.0        1.0  ...  1.0  13.0        6.0     8.0\n",
       "3              0.0     1.0       1.0        1.0  ...  1.0  11.0        6.0     8.0\n",
       "4              0.0     0.0       0.0        1.0  ...  0.0   8.0        5.0     8.0\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /Workspace/Users/liu20@uchicago.edu/diabetes.csv\n",
    "df = pd.read_csv(data_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a94ae905-2620-4ff2-ac42-a6b111c261ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70692, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1752d887-482b-49a0-8ad5-9b00667eeac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67f0c272-cf52-442c-8bc9-5600ebd60722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    35346\n",
       "1.0    35346\n",
       "Name: Diabetes_binary, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Diabetes_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "937fba3c-4069-4603-966f-5ffd34fee859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Train/test split with stratify technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "601d48e2-9510-48be-aaf9-eeb5fe121587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " 0.0    0.5\n",
      "1.0    0.5\n",
      "Name: Diabetes_binary, dtype: float64\n",
      "Test class distribution:\n",
      " 1.0    0.5\n",
      "0.0    0.5\n",
      "Name: Diabetes_binary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Diabetes_binary'])  \n",
    "y = df['Diabetes_binary']  \n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.1,  # 10% for test\n",
    "    stratify=y,     # Stratify by the target variable\n",
    "    random_state=42 # Ensure reproducibility\n",
    ")\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df['Diabetes_binary'] = y_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df['Diabetes_binary'] = y_test\n",
    "\n",
    "# Check class balance in train and test sets\n",
    "print(\"Train class distribution:\\n\", train_df['Diabetes_binary'].value_counts(normalize=True))\n",
    "print(\"Test class distribution:\\n\", test_df['Diabetes_binary'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69155b87-b698-4d61-a896-7b298c774b33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Model inference on test set & model monitoring with Evidently AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a730e9c5-a973-4a23-ad4d-206ea127aac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65435</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35694</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66509</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18354</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58339</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44438</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24442</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7070 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HighBP  HighChol  CholCheck   BMI  ...  Sex   Age  Education  Income\n",
       "65435     1.0       1.0        1.0  35.0  ...  0.0   6.0        6.0     7.0\n",
       "35694     1.0       1.0        1.0  55.0  ...  1.0   5.0        6.0     1.0\n",
       "66509     1.0       1.0        1.0  36.0  ...  0.0   8.0        6.0     5.0\n",
       "18354     1.0       0.0        1.0  34.0  ...  0.0  11.0        6.0     8.0\n",
       "58339     1.0       1.0        1.0  27.0  ...  0.0  13.0        4.0     4.0\n",
       "...       ...       ...        ...   ...  ...  ...   ...        ...     ...\n",
       "44438     1.0       0.0        1.0  30.0  ...  1.0   8.0        4.0     6.0\n",
       "47342     1.0       0.0        1.0  28.0  ...  0.0  11.0        4.0     4.0\n",
       "2151      1.0       0.0        1.0  19.0  ...  0.0   9.0        6.0     7.0\n",
       "24442     0.0       1.0        1.0  27.0  ...  0.0  13.0        4.0     6.0\n",
       "12839     1.0       1.0        1.0  32.0  ...  0.0   7.0        4.0     6.0\n",
       "\n",
       "[7070 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fd8762-113e-4a95-ac27-a4a660fb6944",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert X_test to payload format\n",
    "payload = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": list(X_test.columns),  # Feature names\n",
    "        \"data\": X_test.values.tolist()    # Feature values (row-wise)\n",
    "    }\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",  \n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ea60239-d561-4cca-ad6b-721514aa9a89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions DataFrame:\n",
      "      Actual  Predicted\n",
      "0        1.0          1\n",
      "1        1.0          1\n",
      "2        1.0          1\n",
      "3        0.0          1\n",
      "4        1.0          1\n",
      "...      ...        ...\n",
      "7065     1.0          1\n",
      "7066     1.0          1\n",
      "7067     0.0          0\n",
      "7068     0.0          1\n",
      "7069     0.0          1\n",
      "\n",
      "[7070 rows x 2 columns]\n",
      "Accuracy: 0.7496\n",
      "F1 Score: 0.7627\n",
      "F2 Score: 0.7872\n",
      "Precision: 0.7250\n",
      "Recall: 0.8045\n",
      "Drift report saved: before_swapping_drift_report.html\n"
     ]
    }
   ],
   "source": [
    "# Send the POST request to the endpoint\n",
    "response = requests.post(model_endpoint, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Extract predictions from the response\n",
    "    predictions = response.json().get(\"predictions\", [])\n",
    "    predictions = pd.Series(predictions, name=\"Predicted\")  # Convert to Pandas Series\n",
    "\n",
    "    # Prepare the Actual and Predicted Data\n",
    "    results = pd.DataFrame({\n",
    "        \"Actual\": y_test.reset_index(drop=True),  # Reset index for alignment\n",
    "        \"Predicted\": predictions\n",
    "    })\n",
    "\n",
    "    print(\"Predictions DataFrame:\")\n",
    "    print(results)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    f2 = fbeta_score(y_test, predictions, beta=2)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Evidently Monitoring Setup\n",
    "    # -------------------------\n",
    "\n",
    "    # Prepare Reference (Training) Data\n",
    "    reference_data = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "    reference_data[\"Target\"] = y_train.reset_index(drop=True)  # Add target column to reference data\n",
    "\n",
    "    # Prepare Current (Test) Data\n",
    "    current_data = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "    current_data[\"Target\"] = predictions  # Add predictions as the target column for monitoring\n",
    "\n",
    "    # Column Mapping\n",
    "    column_mapping = ColumnMapping(\n",
    "        target=\"Target\",  # Target column (Actual for Reference, Predicted for Current)\n",
    "        prediction=None,  # No explicit prediction column in Evidently for this report\n",
    "        numerical_features=X_test.columns.tolist()  # List of numerical feature columns\n",
    "    )\n",
    "\n",
    "    # Generate Evidently Reports\n",
    "    drift_report = Report(metrics=[DataDriftPreset(), TargetDriftPreset()])\n",
    "    drift_report.run(reference_data=reference_data, current_data=current_data, column_mapping=column_mapping)\n",
    "\n",
    "    # Save Evidently Reports\n",
    "    drift_report.save_html(\"before_swapping_drift_report.html\")\n",
    "\n",
    "    print(\"Drift report saved: before_swapping_drift_report.html\")\n",
    "\n",
    "else:\n",
    "    print(\"Error Response:\", response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03fbfdad-dcc9-41cc-84f2-5b55f73acce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Log model performance on test set before swapping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16cfe9c-427c-4e59-aa3d-55b7fe128f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging BEFORE swapping metrics and confusion matrix...\n",
      "Confusion matrix saved and logged to MLflow: before_swapping_confusion_matrix.png\n",
      "Metrics and confusion matrix for BEFORE swapping logged.\n",
      "🏃 View run Model Eval Before Swapping at: https://dbc-cc567933-f83f.cloud.databricks.com/ml/experiments/1016961041466494/runs/87d987a79c8f41bf81c78258863bd85a\n",
      "🧪 View experiment at: https://dbc-cc567933-f83f.cloud.databricks.com/ml/experiments/1016961041466494\n"
     ]
    }
   ],
   "source": [
    "def plot_and_log_confusion_matrix(y_true, y_pred, title, filename, prefix=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    # Log the plot as an artifact\n",
    "    mlflow.log_artifact(filename, artifact_path=f\"plots/{prefix}\")\n",
    "    print(f\"Confusion matrix saved and logged to MLflow: {filename}\")\n",
    "\n",
    "# mlflow.end_run()\n",
    "\n",
    "# Start a single MLflow run for both before and after swapping\n",
    "with mlflow.start_run(run_name=\"Model Eval Before Swapping\"):\n",
    "\n",
    "    # ---- BEFORE SWAPPING ----\n",
    "    print(\"Logging BEFORE swapping metrics and confusion matrix...\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics_before = {\n",
    "        \"Accuracy\": accuracy_score(y_test, predictions),\n",
    "        \"F1_Score\": f1_score(y_test, predictions),\n",
    "        \"F2_Score\": fbeta_score(y_test, predictions, beta=2),\n",
    "        \"Precision\": precision_score(y_test, predictions),\n",
    "        \"Recall\": recall_score(y_test, predictions)\n",
    "    }\n",
    "\n",
    "    # Log metrics\n",
    "    for key, value in metrics_before.items():\n",
    "        mlflow.log_metric(f\"before_{key}\", value)\n",
    "\n",
    "    # Create and log the confusion matrix\n",
    "    plot_and_log_confusion_matrix(\n",
    "        y_true=y_test.reset_index(drop=True),\n",
    "        y_pred=predictions,\n",
    "        title=\"Confusion Matrix Before Swapping\",\n",
    "        filename=\"before_swapping_confusion_matrix.png\",\n",
    "        prefix=\"before\"\n",
    "    )\n",
    "\n",
    "    # Log the monitoring report generated previously\n",
    "    mlflow.log_artifact(\"before_swapping_drift_report.html\", artifact_path=\"evidently_reports\")\n",
    "\n",
    "    print(\"Metrics and confusion matrix for BEFORE swapping logged.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da12045f-23fb-4d24-8616-9cf786233e36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Swap features and evaluate model performance again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "211aaa3b-152d-4a81-83de-706ff6dfd9db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature swapping and logging metrics and confusion matrix...\n",
      "Confusion matrix saved and logged to MLflow: after_swapping_confusion_matrix.png\n",
      "Metrics and confusion matrix for AFTER swapping logged.\n",
      "Generating Evidently reports...\n",
      "Drift report saved and logged: after_swapping_drift_report.html\n",
      "🏃 View run Model Eval After Swapping at: https://dbc-cc567933-f83f.cloud.databricks.com/ml/experiments/1016961041466494/runs/0dcaedb7def34ded8465389374bd08cb\n",
      "🧪 View experiment at: https://dbc-cc567933-f83f.cloud.databricks.com/ml/experiments/1016961041466494\n"
     ]
    }
   ],
   "source": [
    "# Perform feature swapping and monitoring\n",
    "with mlflow.start_run(run_name=\"Model Eval After Swapping\"):\n",
    "    print(\"Performing feature swapping and logging metrics and confusion matrix...\")\n",
    "\n",
    "    # ---- SWAP FEATURES ----\n",
    "    X_test_swapped = X_test.copy()\n",
    "    X_test_swapped[\"MentHlth\"], X_test_swapped[\"BMI\"] = X_test_swapped[\"BMI\"], X_test_swapped[\"MentHlth\"]\n",
    "\n",
    "    # Prepare payload with swapped features\n",
    "    payload_swapped = {\n",
    "        \"dataframe_split\": {\n",
    "            \"columns\": list(X_test_swapped.columns),\n",
    "            \"data\": X_test_swapped.values.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Send inference request with swapped features\n",
    "    response_swapped = requests.post(model_endpoint, headers=headers, data=json.dumps(payload_swapped))\n",
    "\n",
    "    if response_swapped.status_code == 200:\n",
    "        # Process predictions\n",
    "        predictions_swapped = response_swapped.json().get(\"predictions\", [])\n",
    "        predictions_swapped = pd.Series(predictions_swapped, name=\"Predicted\")\n",
    "\n",
    "        # ---- METRICS AFTER SWAPPING ----\n",
    "        metrics_after = {\n",
    "            \"Accuracy\": accuracy_score(y_test, predictions_swapped),\n",
    "            \"F1_Score\": f1_score(y_test, predictions_swapped),\n",
    "            \"F2_Score\": fbeta_score(y_test, predictions_swapped, beta=2),\n",
    "            \"Precision\": precision_score(y_test, predictions_swapped),\n",
    "            \"Recall\": recall_score(y_test, predictions_swapped)\n",
    "        }\n",
    "\n",
    "        # Log metrics\n",
    "        for key, value in metrics_after.items():\n",
    "            mlflow.log_metric(f\"after_{key}\", value)\n",
    "\n",
    "        # Create and log the confusion matrix\n",
    "        plot_and_log_confusion_matrix(\n",
    "            y_true=y_test.reset_index(drop=True),\n",
    "            y_pred=predictions_swapped,\n",
    "            title=\"Confusion Matrix After Swapping\",\n",
    "            filename=\"after_swapping_confusion_matrix.png\",\n",
    "            prefix=\"after\"\n",
    "        )\n",
    "\n",
    "        print(\"Metrics and confusion matrix for AFTER swapping logged.\")\n",
    "\n",
    "        # ---- EVIDENTLY MONITORING ----\n",
    "        print(\"Generating Evidently reports...\")\n",
    "\n",
    "        # Prepare Reference (Training) Data\n",
    "        reference_data = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "        reference_data[\"Target\"] = y_train.reset_index(drop=True)\n",
    "\n",
    "        # Prepare Current (Swapped Test) Data\n",
    "        current_data = pd.DataFrame(X_test_swapped, columns=X_test_swapped.columns)\n",
    "        current_data[\"Target\"] = predictions_swapped.reset_index(drop=True)\n",
    "\n",
    "        # Column Mapping for Evidently\n",
    "        column_mapping = ColumnMapping(\n",
    "            target=\"Target\",  # Target column (Actual for Reference, Predicted for Current)\n",
    "            prediction=None,  # No explicit prediction column\n",
    "            numerical_features=X_test.columns.tolist()  # Numerical features\n",
    "        )\n",
    "\n",
    "        # Generate Evidently Reports\n",
    "        drift_report = Report(metrics=[DataDriftPreset(), TargetDriftPreset()])\n",
    "        drift_report.run(reference_data=reference_data, current_data=current_data, column_mapping=column_mapping)\n",
    "\n",
    "        # Save Evidently Reports\n",
    "        drift_report.save_html(\"after_swapping_drift_report.html\")\n",
    "\n",
    "        # Log Drift Report to MLflow\n",
    "        mlflow.log_artifact(\"after_swapping_drift_report.html\", artifact_path=\"evidently_reports\")\n",
    "        print(\"Drift report saved and logged: after_swapping_drift_report.html\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error during inference with swapped features:\", response_swapped.json())\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "diabetes_model_inference",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
